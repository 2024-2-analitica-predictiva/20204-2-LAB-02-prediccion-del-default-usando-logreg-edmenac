{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edmc9\\Documents\\GitHub\\Especializacion_Analitica\\Analitica_predictiva\\20204-2-LAB-02-prediccion-del-default-usando-logreg-edmenac\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\edmc9\\Documents\\GitHub\\Especializacion_Analitica\\Analitica_predictiva\\20204-2-LAB-02-prediccion-del-default-usando-logreg-edmenac\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\edmc9\\Documents\\GitHub\\Especializacion_Analitica\\Analitica_predictiva\\20204-2-LAB-02-prediccion-del-default-usando-logreg-edmenac\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas y matrices de confusión guardadas exitosamente en ../files/output/metrics.json\n"
     ]
    }
   ],
   "source": [
    "# flake8: noqa: E501\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Paso 1: Limpieza de los datasets\n",
    "def preprocess(df):\n",
    "    df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "    df.drop(columns=['ID'], inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df['EDUCATION'] = df['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "    df['EDUCATION'] = df['EDUCATION'].astype('int64')\n",
    "    return df\n",
    "\n",
    "train_pre = pd.read_csv('../files/input/train_data.csv.zip', compression='zip', index_col=None)\n",
    "test_pre = pd.read_csv('../files/input/test_data.csv.zip', compression='zip', index_col=None)\n",
    "\n",
    "train = preprocess(train_pre)\n",
    "test = preprocess(test_pre)\n",
    "\n",
    "# Paso 2: División de los datasets\n",
    "x_train = train.drop(columns=['default'])\n",
    "y_train = train['default']\n",
    "x_test = test.drop(columns=['default'])\n",
    "y_test = test['default']\n",
    "\n",
    "# Paso 3: Crear pipeline\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "# categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "numerical_features = list(set(x_train.columns) - set(categorical_features))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', MinMaxScaler(), numerical_features)\n",
    "]\n",
    ")\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"selector\", SelectKBest(f_classif)),\n",
    "        (\"classifier\", LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# param_grid = {\n",
    "#     'feature_selection__k': [5, 10, 15],  # Selección del número de características a retener\n",
    "#     'classifier__C': [0.0001, 0.01, 0.1, 1, 10, 100, 10000],  # Regularización de la regresión logística (parámetro C)\n",
    "#     'classifier__solver': ['liblinear', 'saga']  # Métodos de optimización para la regresión logística\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "        \"selector__k\": [5, 10, 15],\n",
    "        \"classifier__C\": [0.1, 1, 10],\n",
    "        'classifier__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     param_grid,\n",
    "#     scoring='balanced_accuracy',\n",
    "#     cv=10,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring=\"balanced_accuracy\")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Paso 5: Guardar el modelo\n",
    "os.makedirs(\"../files/models\", exist_ok=True)\n",
    "with open(\"../files/models/model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(grid_search, file)\n",
    "\n",
    "# Paso 6 y 7: Calcular métricas y guardar resultados\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": dataset_name,\n",
    "        \"precision\": float(precision),\n",
    "        \"balanced_accuracy\": float(balanced_accuracy),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1)\n",
    "    }\n",
    "\n",
    "def calculate_cm(y_true, y_pred, dataset_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": dataset_name,\n",
    "        \"true_0\": {\"predicted_0\": int(cm[0, 0]), \"predicted_1\": int(cm[0, 1])},\n",
    "        \"true_1\": {\"predicted_0\": int(cm[1, 0]), \"predicted_1\": int(cm[1, 1])}\n",
    "    }\n",
    "\n",
    "# Predicciones\n",
    "train_preds = grid_search.best_estimator_.predict(x_train)\n",
    "test_preds = grid_search.best_estimator_.predict(x_test)\n",
    "\n",
    "metrics = [\n",
    "    calculate_metrics(y_train, train_preds, \"train\"),\n",
    "    calculate_metrics(y_test, test_preds, \"test\"),\n",
    "    calculate_cm(y_train, train_preds, \"train\"),\n",
    "    calculate_cm(y_test, test_preds, \"test\")\n",
    "]\n",
    "\n",
    "# Guardar métricas y matrices de confusión en JSON\n",
    "os.makedirs('../files/output', exist_ok=True)\n",
    "output_file = '../files/output/metrics.json'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(f\"Métricas y matrices de confusión guardadas exitosamente en {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
